# 1. 框架

> 王辉
>
> 2022/3/25

[TOC]



## 1.1  计算图

随着机器学习的机器学习的不断发展，模型具有越来越复杂的拓扑结构，这些复杂的拓扑结构会影响模型算子的执行，自动化计算梯度(自动微分)和训练参数的自动化判断，因此，计算图孕育而生。

![image-20220325104228448](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325104228448.png)

神经网络框架最重要的就是构建计算图分析模型定义和自动化计算梯度；虽然用户给定的模型“串行化”的连接多个神经网络层，但是可以通过计算图分析模型算子的执行关系，更好的发现算子进行异步执行的机会，以更快的速度完成程序的执行。

![image-20220325111305052](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325111305052.png)

相互独立的部分可以并行计算，这为计算图的优化提供了巨大的空间。

---

计算图由基本运算单元算子(Operator)和数据张量(Tensor)构成。其中，节点表示算子操作，边表示数据张量。

![image-20220325105144709](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325105144709.png)

> 参考：https://baijiahao.baidu.com/s?id=1689914224752955739&wfr=spider&for=pc

**辨析动态图和静态图：**

PyTorch中的计算图是动态的，因此在每次迭代时都会从头开始重新创建，这正是允许使用任意Python控制流语句的原因，所以问题**静态图怎么处理分支结构、判断语句呢？** 因为动态图的好处，可以在每次迭代时更改图的整体形状和大小，不必对所有可能的路径进行编码，运行即所得。

从概念上讲，autograd在执行操作时保留创建数据的所有操作的图形记录，生成一个有向无环图，并且使用链式法则自动计算梯度。

---

张量数据的存储状态可以分为可变和不可变两种，不可变张量一般用于用户初始化的数据或者网络模型输入的数据；而可变张量则存储网络权重参数，根据梯度信息更新自身数据。常见的激活函数包括S型生长曲线(Sigmoid)、线性矫正单元(Rectified Linear Unit, ReLU)等。常见的优化算法有随机梯度下降法(Stochastic Gradient Descent, SGD)、自适应矩估计(Adaptive Moment Estimation, Adam)等。

----

在构建计算题的时候要极力避免算子之间的循环依赖

![image-20220325111632826](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325111632826.png)



在深度学习中，**这种循环关系是以 展开机制(Unrolling)机制展开的，** 每一个张量和运算符都具有独特的标识符，即使是相同的操作运算，在参与不同计算任务时都具有不同的标识符。

![image-20220325111816695](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325111816695.png)

> 区分循环关系和循环依赖的关键在于，是否两个独特标识符之间的运算互相具有直接依赖和相互依赖。循环关系在展开复制计算子图的时候会给复制的所有张量和运算符赋予新的标识符，区分被复制的原始子图，以避免形成循环依赖。



### Q1: 控制流

**就像最前面所说，动态图可以无视控制流，每次操作都会重新构图，运行即所得，但是静态图的分支语句怎么进行存储呢，因为模型始终要维护的是一张图。**

了提高性能、可扩展性和表达能力，计算框架必须支持控制流：

- 图内方法（In-graph approach,**计算框架控制原语**):  计算框架在内部设计了低级别细粒度的控制原语运算符，通过原语运算符的结合使用来实现控制流，TensorFlow中的Switch、Merge、Enter、Exit、NextIteration五个原语。TensorFlow通过组合五个原语提供 *tf.cond()* 和 *tf.while_loop()* 来实现条件控制和循环控制。
- 图外方法（Out-of-graph approach，**前端语言控制流** ): 计算框架PyTorch、MindSpore中就**直接使用Python的控制流**，将控制流和数据流之间保持了严格的分离。 【疑问：直接使用Python的控制流，那就限制了这些模型也只能是使用Python语言了，做不到语言之间的迁移了】

图内方法采用框架原语实现，不依赖外部语言便于部署到不同环境中去，并且让模型准确判定计算梯度时需要缓存的变量，提高运行效率。图外方法则直接使用灵活易用的前端控制语言，更加直观便捷，但是后续若进行优化，需要将前端语言的控制流转化为框架原语描述。



###Q2: 动态图和静态图区别

> 在计算框架中可以生成静态图和动态图两种计算图。静态图对应声明式编程范式，动态图对应命令式编程范式。静态生成可以根据前端语言描述的神经网络拓扑结构以及参数变量等信息构建一份固定的计算图，因此静态图在执行期间可以不依赖前端语言描述，常用于神经网络模型的部署，比如移动端人脸识别场景中的应用等。动态图则需要在每一次执行神经网络模型依据前端语言描述动态生成一份临时的计算图，这意味着计算图的动态生成过程灵活可变，该特性有助于我们在神经网络结构调整阶段提高效率。主流计算框架TensorFlow、MindSpore均支持动态图和静态图模式；PyTorch则可以通过工具将构建的动态图神经网络模型转化为静态结构，以获得高效的计算执行效率。

- **静态图**

静态图采用先编译后执行的方式，将计算图的定义和执行分离，静态图使用前端语言定义模型后，并不使用前端语言解释器执行，而是将前端描述的完整模型交给框架，静态图可以使用优化策略转换成更加高效的结构。

![image-20220325114853964](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325114853964.png)

由于在进行静态生成编译时并不读取输入数据，此时需要一种特殊的张量来表示输入数据辅助构建完整的计算图，这种特殊张量就被称之为”数据占位符”。在上述的伪代码中输入数据 **X** 需要使用占位符在静态图中表示。由于在静态图模式下构建网络并没有执行任何计算，对于条件控制在编译阶段并不会进行逻辑运算完成判断，因此需要将条件控制算子以及所有的分支计算子图加入计算图中。在执行阶段网络接受数据流入，调度条件控制算子时进行逻辑判断，控制数据流入不同的分支计算子图中进行后续计算。**由于控制流和静态生成的特殊性，在部分计算框架中前端语言Python的控制流不能够被正确编译为等价的静态图结构，因此需要使用复杂的图内方法实现控制流。**



经过编译后获取完整的计算图，能够根据全局信息完成图优化策略，进行编译优化形成与模型完全等价的静态图。优化手段包括硬件算子选择、内存分配、内存复用等，提高算子执行效率和内存利用效率，降低内存开销。

静态生成采用先编译后执行的方式，编译阶段和执行阶段分离，前端语言构建的神经网络模型经过编译后，计算图结构便固定执行阶段不再改变，并且经过优化用于执行的计算图结构与原始代码有较大的差距，导致代码中的错误难以定位到准确位置，增加了代码调试难度。此外在神经网络模型开发迭代环节，不能即时打印中间结果。

- **动态图**

动态图采用解析式的执行方式， 编译与执行同时执行，动态图采用前端语言自身的解释器对代码进行解析，利用计算框架本身的算子分发功能，算子会即刻执行并输出结果。

![image-20220325123244919](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325123244919.png)

 静态图和动态图本质区别在于静态生成和动态生成的编译执行过程不同，动态生成并不采用计算框架编译器生成的完整的静态计算图，而是使用前端语言的解释器Python API调用计算框架，框架利用自身的算子分发过程，将Python调用的算子在相应硬件上进行加速计算，然后将结构返回前端。该过程并不产生静态的计算图，而是按照前端语言描述模型结构，按照计算依赖关系进行调度计算，动态生成临时的图拓扑结构。

![image-20220325143032219](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325143032219.png)

相比于静态生成，动态生成的图并不能完整表示前端语言描述的模型结构，需要根据控制条件和数据流向产生图结构。并且由于计算狂阶无法通过动态生成获取完整的图结构，动态图模式难以进行图结构优化来提高计算效率。



### Q3: 动态图转化为静态图

目前TensorFlow、MindSpore、PyTorch、PaddlePaddle等主流计算框架均具备动态图转静态图的功能，支持使用动态图编写代码，框架自动转换为静态图网络结构。

动态图转换为静态图的实现方式有两种：

- **基于追踪转换** ：以动态图模式执行并记录调度的算子，构建和保存为静态图模型。
- **基于源码转换** ：分析前端代码来将动态图代码自动转写为静态图代码，并在底层自动帮用户使用静态图执行器运行。

```python
基于追踪转换 的原理相对简单，当使用动态图模式构建好网络后，使用追踪（Tracing）进行转换将分为两个阶段。第一个阶段计算框架会创建一个新的计算图，此时以动态图模式执行代码，计算框架会自动追踪数据流的流动以及算子的调度，将所有的操作捕获并根据调度顺序构建静态图模型。第二个阶段，当执行完一次动态图后，计算框架已生成静态图，当再次调用相同的模型时，计算框架会自动指向静态图模型，以高效的性能执行计算。追踪技术只是记录第一次执行动态图时调度的算子，但若是模型中存在依赖于中间结果的条件分支控制流，只能追踪到根据第一次执行时触发的分支。此时构建的静态图模型并不是完整的，缺失了数据未流向的其他分支。在后续的调用中，因为静态模型已无法再改变，若计算过程中数据流向缺失分支会导致模型运行错误。同样的，依赖于中间数据结果的循环控制也无法追踪到全部的迭代状态。
```

==问题==  如果图中出现条件分支，但是动态图只是某一条分支，根据动态图生成的静态图就缺失了数据未流向的其他分支，进而导致模型运行错误。

```python
基于源码转换 的方式则能够改善基于追踪转换的缺陷。
基于源码转换的流程经历两个阶段。
# 第一个阶段，对动态图模式下的代码扫描进行词法分析，通过词法分析器分析源代码中的所有字符，对代码进行分割并移除空白符、注释等，将所有的单词或字符都转化成符合规范的语法单元列表。接着进行语法分析即解析器，将得到的语法单元列表转换成树形式，并对语法进行检查避免错误。
# 第二阶段，动态图转静态图的核心部分就是对抽象语法树进行转写，计算框架中对每一个需要转换的语法都预设有转换器，每一个转换器对语法树进行扫描改写，将动态图代码语法映射为静态图代码语法。其中最为重要的前端语言控制流，会在这一阶段分析转换为静态图接口进行实现。转写完毕之后，将新的语法树再还原回静态图代码，就可以使用静态生成执行。
使用该方式可以避免基于追踪转换中控制流表达缺失的情况。
```



![image-20220325151831332](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325151831332.png)

通过源码转换，可以将整体模型全部代码全部转换为静态图代码，同时也可以将整体模型的部分函数转化为局部静态子图，静态子图会被计算框架视为一个完整的算子并嵌入动态图中。

![image-20220325152145106](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325152145106.png)



### Q4: 计算图的调度

计算图中算子存在直接或间接依赖关系，具有依赖关系的算子间任务调度存在执行的时间关系。

![image-20220325152653391](https://gitee.com/wanghui88888888/picture/raw/master/img/image-20220325152653391.png)



计算图中存在算子独立的情况，因此可以将两个算子分配到两个硬件上并行计算，缩短执行时间。

==并行包括: `1.算子并行` `2.模型并行` `3. 数据并行`==

**算子并行**不仅可以在相互独立的算子间执行，同时也可以将单个算子合理的切分为相互独立的两个子操作，进一步提高并行性。

**模型并行**就是将整体计算图进行合理的切分，分配到不同设备上进行并行计算，缩短单次计算图迭代训练时间。

**数据并行**则同时以不同的数据训练多个相同结构的计算图，缩短训练迭代次数，加快训练效率。





























